{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 簡介\n",
        "本Colab筆記本展示如何使用LangGraph實作三個Agentic Pattern：ReAct（公司用語生成）、Reflection（電子郵件改寫）和Hierarchical Workflow（文章翻譯）。您將學會定義節點、邊和狀態，建構模組化AI工作流程，應用於正式用語生成、郵件優化和多語言翻譯。\n",
        "\n",
        "**學習成果**：\n",
        "- 掌握LangGraph的核心功能（節點、邊、狀態管理）。\n",
        "- 實現公司用語、電子郵件改進和文章翻譯的AI代理。\n",
        "- 理解AI從單一代理到協作流程的應用。\n",
        "\n",
        "**先決條件**：熟悉Python，需提供OpenAI API金鑰以進行LLM調用。\n",
        "\n",
        "執行以下程式碼，安裝必要套件並開始實作！"
      ],
      "metadata": {
        "id": "ey-jCSIOMt9u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8j49jElK8VR"
      },
      "outputs": [],
      "source": [
        "!pip install -q langgraph openai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 實作1：ReAct - 公司用語生成\n",
        "本實作建構一個簡化的ReAct代理，生成正式的公司用語，例如將會議筆記轉為專業會議記錄。代理執行最多2次生成，確保穩定性，避免依賴LLM動態決策。\n",
        "\n",
        "**目標：**\n",
        "實現一個穩定的ReAct代理，生成公司用語。\n",
        "\n",
        "**步驟：**\n",
        "1. 定義狀態（輸入、歷史、結果、迭代次數）。\n",
        "2. 創建生成節點（產生用語）、檢查節點（記錄迭代）。\n",
        "3. 配置邊，固定2次迭代後結束。"
      ],
      "metadata": {
        "id": "Oq2htxnaN3fE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "@dataclass\n",
        "class ReActState:\n",
        "    input: str\n",
        "    history: list\n",
        "    result: str = \"\"\n",
        "    iteration: int = 0\n",
        "\n",
        "# 設定OpenAI API\n",
        "client = OpenAI(api_key=userdata.get('OPENAI_API_KEY'))  # 請替換為您的API金鑰\n",
        "\n",
        "def llm_call(prompt: str, max_tokens: int = 100) -> str:\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        max_tokens=max_tokens\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "def generate_node(state: ReActState) -> Dict:\n",
        "    prompt = f\"將以下內容轉為正式公司用語：\\n{state.input}\\n歷史：{state.history}\"\n",
        "    state.result = llm_call(prompt)\n",
        "    state.history.append(f\"生成：{state.result}\")\n",
        "    return {\"result\": state.result, \"history\": state.history}\n",
        "\n",
        "def check_node(state: ReActState) -> Dict:\n",
        "    state.iteration += 1\n",
        "    return {\"iteration\": state.iteration}\n",
        "\n",
        "workflow = StateGraph(ReActState)\n",
        "workflow.add_node(\"generate\", generate_node)\n",
        "workflow.add_node(\"check\", check_node)\n",
        "workflow.set_entry_point(\"generate\")\n",
        "workflow.add_edge(\"generate\", \"check\")\n",
        "workflow.add_conditional_edges(\n",
        "    \"check\",\n",
        "    lambda state: \"end\" if state.iteration >= 2 else \"generate\",\n",
        "    {\"generate\": \"generate\", \"end\": END}\n",
        ")\n",
        "graph = workflow.compile()\n",
        "\n",
        "# 執行\n",
        "result = graph.invoke(ReActState(input=\"會議討論了新產品發布\", history=[]))\n",
        "print(f\"最終用語：{result['result']}\")\n",
        "print(f\"生成歷史：{result['history']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aejiWVWOMzpV",
        "outputId": "a3f42369-bb25-49af-b09b-eaa3826c636f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "最終用語：在本次會議中討論了公司新產品發布計畫。公司歷史紀錄中無相關資訊。\n",
            "生成歷史：['生成：會議研討了新產品發布計畫。\\n公司歷史：[]', '生成：在本次會議中討論了公司新產品發布計畫。公司歷史紀錄中無相關資訊。']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 實作2：Reflection - 電子郵件改寫\n",
        "本實作建構一個Reflection代理，改進電子郵件的語氣和結構，例如將草稿改為更專業的版本。代理透過LLM反思並優化郵件內容。\n",
        "\n",
        "**目標**：實現一個Reflection代理，改進電子郵件。\n",
        "\n",
        "**步驟：**\n",
        "1. 定義狀態（草稿、郵件、反饋）。\n",
        "2. 創建生成節點（改寫郵件）、反思節點（檢查問題）、更新節點（修正郵件）。\n",
        "3. 配置邊與條件邏輯。"
      ],
      "metadata": {
        "id": "3aIWlm_GSClF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict\n",
        "from openai import OpenAI\n",
        "\n",
        "@dataclass\n",
        "class ReflectionState:\n",
        "    draft: str\n",
        "    email: str = \"\"\n",
        "    feedback: str = \"\"\n",
        "    has_issue: bool = False\n",
        "\n",
        "# 設定OpenAI API\n",
        "client = OpenAI(api_key=userdata.get('OPENAI_API_KEY'))  # 請替換為您的API金鑰\n",
        "\n",
        "def llm_call(prompt: str, max_tokens: int = 200) -> str:\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        max_tokens=max_tokens\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "def generate_node(state: ReflectionState) -> Dict:\n",
        "    prompt = f\"將以下電子郵件草稿改為專業語氣：\\n{state.draft}\"\n",
        "    state.email = llm_call(prompt)\n",
        "    return {\"email\": state.email}\n",
        "\n",
        "def reflect_node(state: ReflectionState) -> Dict:\n",
        "    prompt = f\"檢查以下電子郵件是否存在語氣或結構問題：\\n{state.email}\\n若有問題，回覆具體建議；若無，回覆'無問題'\"\n",
        "    state.feedback = llm_call(prompt)\n",
        "    state.has_issue = \"無問題\" not in state.feedback\n",
        "    return {\"feedback\": state.feedback, \"has_issue\": state.has_issue}\n",
        "\n",
        "def update_node(state: ReflectionState) -> Dict:\n",
        "    prompt = f\"基於以下建議修正電子郵件：\\n建議：{state.feedback}\\n原始郵件：\\n{state.email}\"\n",
        "    state.email = llm_call(prompt)\n",
        "    return {\"email\": state.email}\n",
        "\n",
        "workflow = StateGraph(ReflectionState)\n",
        "workflow.add_node(\"generate\", generate_node)\n",
        "workflow.add_node(\"reflect\", reflect_node)\n",
        "workflow.add_node(\"update\", update_node)\n",
        "workflow.set_entry_point(\"generate\")\n",
        "workflow.add_edge(\"generate\", \"reflect\")\n",
        "workflow.add_conditional_edges(\n",
        "    \"reflect\",\n",
        "    lambda state: \"update\" if state.has_issue else \"end\",\n",
        "    {\"update\": \"update\", \"end\": END}\n",
        ")\n",
        "workflow.add_edge(\"update\", \"reflect\")\n",
        "graph = workflow.compile()\n",
        "\n",
        "# 執行\n",
        "result = graph.invoke(ReflectionState(draft=\"嗨，明天可以開會嗎？\"))\n",
        "print(f\"最終郵件：\\n{result['email']}\")\n",
        "print(f\"反饋：{result['feedback']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXH35NMfM7-R",
        "outputId": "ac2d427d-78ec-40ad-e2e9-1869c329c21f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "最終郵件：\n",
            "論非常有價值。\n",
            "\n",
            "若您能參加，請回覆郵件，告訴我們您的方便時間，我們將安排會議時間。期待您的回覆。\n",
            "\n",
            "謝謝！\n",
            "\n",
            "XXX公司發展部門 敬上\n",
            "反饋：這封電子郵件看起來沒有明顯的語氣或結構問題。建議可以加上更具體的內容，例如提供會議主題或目的，以便收件人更清楚了解。另外，要求收件人回覆具體建議或回覆'無問題'也是一個很好的做法。如果想要更加正式或專業，可以適當地修改郵件內容。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "延伸練習：\n",
        "- 將draft改為其他郵件草稿（例如「請審核文件」）。\n",
        "- 檢查feedback的改進建議。\n",
        "- 調整reflect_node的提示，檢查特定問題（例如清晰度）。"
      ],
      "metadata": {
        "id": "UbVXSbCNR64W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "apZWRvuURnP-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 實作3：Hierarchical Workflow - 文章翻譯\n",
        "本實作建構一個Hierarchical Workflow，模擬文章翻譯場景，例如將英文文章翻譯成中文並校對。監督代理分配翻譯或校對任務，子代理執行相應工作。\n",
        "\n",
        "**目標**：實現一個層次化工作流程，完成文章翻譯與校對。\n",
        "\n",
        "**步驟：**\n",
        "\n",
        "1. 定義狀態（任務類型、原文、翻譯）。\n",
        "2. 創建監督節點（分配任務）、翻譯節點（生成翻譯）、校對節點（檢查翻譯）。\n",
        "3. 配置邊與邏輯。"
      ],
      "metadata": {
        "id": "fAqM6OmxRjHI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict\n",
        "from openai import OpenAI\n",
        "\n",
        "@dataclass\n",
        "class WorkflowState:\n",
        "    task_type: str\n",
        "    source: str = \"\"\n",
        "    translation: str = \"\"\n",
        "    agent: str = \"\"\n",
        "\n",
        "# 設定OpenAI API\n",
        "client = OpenAI(api_key=userdata.get('OPENAI_API_KEY'))  # 請替換為您的API金鑰\n",
        "\n",
        "def llm_call(prompt: str, max_tokens: int = 200) -> str:\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        max_tokens=max_tokens\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "def supervisor_node(state: WorkflowState) -> Dict:\n",
        "    prompt = f\"任務類型：{state.task_type}\\n選擇代理：僅回覆'translate_agent'或'proofread_agent'\"\n",
        "    response = llm_call(prompt, max_tokens=10)\n",
        "    # 清理回應，確保僅為'translate_agent'或'proofread_agent'\n",
        "    state.agent = 'translate_agent' if 'translate' in response.lower() else 'proofread_agent'\n",
        "    return {\"agent\": state.agent}\n",
        "\n",
        "def translate_node(state: WorkflowState) -> Dict:\n",
        "    prompt = f\"將以下英文翻譯成中文：\\n{state.source}\"\n",
        "    state.translation = llm_call(prompt)\n",
        "    state.task_type = \"proofread\"  # 模擬後續校對\n",
        "    return {\"translation\": state.translation, \"task_type\": state.task_type}\n",
        "\n",
        "def proofread_node(state: WorkflowState) -> Dict:\n",
        "    prompt = f\"校對以下翻譯，確保語法和語義正確：\\n原文：{state.source}\\n翻譯：{state.translation}\"\n",
        "    state.translation = llm_call(prompt)\n",
        "    return {\"translation\": state.translation}\n",
        "\n",
        "workflow = StateGraph(WorkflowState)\n",
        "workflow.add_node(\"supervisor\", supervisor_node)\n",
        "workflow.add_node(\"translate\", translate_node)\n",
        "workflow.add_node(\"proofread\", proofread_node)\n",
        "workflow.set_entry_point(\"supervisor\")\n",
        "workflow.add_conditional_edges(\n",
        "    \"supervisor\",\n",
        "    lambda state: state.agent,\n",
        "    {\"translate_agent\": \"translate\", \"proofread_agent\": \"proofread\"}\n",
        ")\n",
        "workflow.add_edge(\"translate\", \"supervisor\")\n",
        "workflow.add_edge(\"proofread\", END)\n",
        "graph = workflow.compile()\n",
        "\n",
        "# 執行\n",
        "result = graph.invoke(WorkflowState(task_type=\"translate\", source=\"AI will transform industries in 2025.\"))\n",
        "print(f\"原文：{result['source']}\")\n",
        "print(f\"翻譯：{result['translation']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RU1olWlQ0VM",
        "outputId": "7c47a9b9-b4ce-4f5b-f0db-2c5841a87d94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "原文：AI will transform industries in 2025.\n",
            "翻譯：校對後翻譯：2025年將會有人工智慧改變產業。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "延伸練習\n",
        "- 將source改為其他英文句子（例如「The future is bright」）。\n",
        "- 檢查translation的內容。\n",
        "- 添加新子代理（例如格式調整代理）。"
      ],
      "metadata": {
        "id": "6LBkuShwReJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rXHxAodEREHW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}