{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf35dbbd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 環境準備\n",
    "!pip install langchain langchain-openai langchain-community openai numpy scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbfe5b7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 導入必要的模組\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.schema import Document\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os\n",
    "\n",
    "# 設定 API 金鑰（請替換為您的實際金鑰）\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-openai-api-key-here\"\n",
    "\n",
    "# 初始化嵌入模型\n",
    "embeddings_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "print(\"嵌入模型初始化完成！\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a504b84",
   "metadata": {},
   "source": [
    "## 探索語義相似性"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbfb1b2",
   "metadata": {},
   "source": [
    "### 生成文本向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945ec59a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 準備測試文本\n",
    "test_texts = [\n",
    "    \"人工智慧正在改變世界\",\n",
    "    \"AI 技術革新了我們的生活方式\", \n",
    "    \"機器學習是 AI 的一個重要分支\",\n",
    "    \"深度學習神經網路模擬人腦結構\",\n",
    "    \"今天天氣很好，陽光明媚\",\n",
    "    \"我喜歡在週末去公園散步\",\n",
    "    \"數據科學家需要掌握統計學知識\",\n",
    "    \"演算法優化可以提升系統效能\"\n",
    "]\n",
    "\n",
    "# 生成嵌入向量\n",
    "print(\"正在生成嵌入向量...\")\n",
    "embeddings = embeddings_model.embed_documents(test_texts)\n",
    "\n",
    "print(f\"成功生成 {len(embeddings)} 個嵌入向量\")\n",
    "print(f\"每個向量的維度：{len(embeddings[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b54edc9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 將嵌入轉換為 numpy 陣列以便分析\n",
    "embeddings_array = np.array(embeddings)\n",
    "print(f\"嵌入矩陣形狀：{embeddings_array.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fe0a32",
   "metadata": {},
   "source": [
    "### 計算相似度矩陣"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5f8d02",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 計算相似度矩陣\n",
    "similarity_matrix = cosine_similarity(embeddings_array)\n",
    "\n",
    "print(\"=== 語義相似度分析 ===\")\n",
    "print(\"文本列表：\")\n",
    "for i, text in enumerate(test_texts):\n",
    "    print(f\"{i}: {text}\")\n",
    "\n",
    "print(\"\\n最相似的文本對：\")\n",
    "# 找出最相似的文本對（排除自己與自己的比較）\n",
    "for i in range(len(test_texts)):\n",
    "    for j in range(i+1, len(test_texts)):\n",
    "        similarity = similarity_matrix[i][j]\n",
    "        if similarity > 0.8:  # 高相似度閾值\n",
    "            print(f\"文本 {i} 和 {j}：相似度 {similarity:.3f}\")\n",
    "            print(f\"  「{test_texts[i]}」\")\n",
    "            print(f\"  「{test_texts[j]}」\")\n",
    "            print()\n",
    "\n",
    "# 找出特定文本的最相關內容\n",
    "target_index = 0  # \"人工智慧正在改變世界\"\n",
    "similarities = similarity_matrix[target_index]\n",
    "sorted_indices = np.argsort(similarities)[::-1][1:]  # 排除自己\n",
    "\n",
    "print(f\"與「{test_texts[target_index]}」最相關的文本：\")\n",
    "for i, idx in enumerate(sorted_indices[:3]):\n",
    "    print(f\"{i+1}. 相似度 {similarities[idx]:.3f}: {test_texts[idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab6051f",
   "metadata": {},
   "source": [
    "## 視覺化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736eac05",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install matplotlib scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d93a8f1",
   "metadata": {},
   "source": [
    "### 設定參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6155b3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "# 使用 PCA 將 1536 維降到 2 維\n",
    "pca = PCA(n_components=2)\n",
    "embeddings_2d = pca.fit_transform(embeddings_array)\n",
    "\n",
    "# 設定中文字體（如果環境支援）\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2c2ae3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 創建視覺化圖表\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], alpha=0.7, s=100)\n",
    "\n",
    "# 為每個點添加標籤\n",
    "for i, txt in enumerate(test_texts):\n",
    "    plt.annotate(f'{i}: {txt[:10]}...', \n",
    "                (embeddings_2d[i, 0], embeddings_2d[i, 1]),\n",
    "                xytext=(5, 5), textcoords='offset points',\n",
    "                fontsize=9, alpha=0.8)\n",
    "\n",
    "plt.title('文本嵌入的二維視覺化\\n(使用 PCA 降維)', fontsize=14)\n",
    "plt.xlabel(f'主成分 1 (解釋變異: {pca.explained_variance_ratio_[0]:.1%})')\n",
    "plt.ylabel(f'主成分 2 (解釋變異: {pca.explained_variance_ratio_[1]:.1%})')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ea1ed8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"PCA 降維保留了 {sum(pca.explained_variance_ratio_):.1%} 的原始變異\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42547ca9",
   "metadata": {},
   "source": [
    "## 向量資料庫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a6f36f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 導入向量資料庫相關模組\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.schema import Document\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "print(\"開始建立向量資料庫...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250258e2",
   "metadata": {},
   "source": [
    "### 建立文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f0e7a4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 創建測試文件\n",
    "sample_documents = [\n",
    "    Document(\n",
    "        page_content=\"機器學習是人工智慧的一個重要分支，它使計算機能夠從數據中學習而無需明確編程。\",\n",
    "        metadata={\"source\": \"ml_intro.txt\", \"category\": \"技術\", \"difficulty\": \"初級\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"深度學習使用多層神經網路來模擬人腦的決策過程，在圖像識別和自然語言處理方面取得了突破性進展。\",\n",
    "        metadata={\"source\": \"dl_guide.txt\", \"category\": \"技術\", \"difficulty\": \"進階\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"數據預處理是機器學習流程中的關鍵步驟，包括數據清理、特徵選擇和標準化等操作。\",\n",
    "        metadata={\"source\": \"data_prep.txt\", \"category\": \"技術\", \"difficulty\": \"中級\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"AI 倫理關注人工智慧系統的公平性、透明度和責任歸屬，確保技術發展符合人類價值觀。\",\n",
    "        metadata={\"source\": \"ai_ethics.txt\", \"category\": \"倫理\", \"difficulty\": \"中級\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"自動駕駛汽車結合了電腦視覺、機器學習和感測器技術，代表了人工智慧在交通領域的重要應用。\",\n",
    "        metadata={\"source\": \"autonomous_cars.txt\", \"category\": \"應用\", \"difficulty\": \"進階\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"自然語言處理讓機器能夠理解和生成人類語言，應用範圍從聊天機器人到機器翻譯都有涉及。\",\n",
    "        metadata={\"source\": \"nlp_overview.txt\", \"category\": \"技術\", \"difficulty\": \"中級\"}\n",
    "    )\n",
    "]\n",
    "\n",
    "print(f\"準備了 {len(sample_documents)} 個示例文件\")\n",
    "for i, doc in enumerate(sample_documents):\n",
    "    print(f\"{i+1}. [{doc.metadata['category']}] {doc.page_content[:30]}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0400264",
   "metadata": {},
   "source": [
    "### 建立一個向量資料庫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7f38c5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 配置 Chroma 資料庫\n",
    "chroma_settings = Settings(\n",
    "    chroma_db_impl=\"duckdb+parquet\",\n",
    "    persist_directory=\"./chroma_db_demo\"\n",
    ")\n",
    "\n",
    "# 建立向量資料庫\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=sample_documents,\n",
    "    embedding=embeddings_model,\n",
    "    persist_directory=\"./chroma_db_demo\",\n",
    "    collection_name=\"ai_knowledge_base\"\n",
    ")\n",
    "\n",
    "print(\"向量資料庫建立完成！\")\n",
    "print(f\"資料庫位置：./chroma_db_demo\")\n",
    "print(f\"集合名稱：ai_knowledge_base\")\n",
    "\n",
    "# 檢查資料庫狀態\n",
    "collection = vector_store._collection\n",
    "print(f\"文件數量：{collection.count()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0ca466",
   "metadata": {},
   "source": [
    "### 向量資料庫檢索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b26ac6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 測試相似度搜尋\n",
    "def test_similarity_search(query, k=3):\n",
    "    print(f\"\\n=== 查詢：「{query}」 ===\")\n",
    "    \n",
    "    # 執行相似度搜尋\n",
    "    results = vector_store.similarity_search(query, k=k)\n",
    "    \n",
    "    print(f\"找到 {len(results)} 個相關文件：\")\n",
    "    for i, doc in enumerate(results):\n",
    "        print(f\"\\n{i+1}. [{doc.metadata['category']} - {doc.metadata['difficulty']}]\")\n",
    "        print(f\"   來源：{doc.metadata['source']}\")\n",
    "        print(f\"   內容：{doc.page_content}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# 測試不同類型的查詢\n",
    "test_queries = [\n",
    "    \"什麼是深度學習？\",\n",
    "    \"如何處理數據？\",\n",
    "    \"AI 的道德問題\",\n",
    "    \"自駕車技術\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    test_similarity_search(query, k=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639c5edb",
   "metadata": {},
   "source": [
    "### 帶分數的檢索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36f89b6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 帶分數的相似度搜尋\n",
    "def test_similarity_search_with_score(query, k=3, score_threshold=0.7):\n",
    "    print(f\"\\n=== 帶分數查詢：「{query}」 ===\")\n",
    "    \n",
    "    # 執行帶分數的相似度搜尋\n",
    "    results_with_scores = vector_store.similarity_search_with_score(query, k=k)\n",
    "    \n",
    "    filtered_results = []\n",
    "    for doc, score in results_with_scores:\n",
    "        # Chroma 使用距離分數，值越小表示越相似\n",
    "        # 我們轉換為相似度分數（1 - 標準化距離）\n",
    "        similarity_score = 1 / (1 + score)\n",
    "        if similarity_score >= score_threshold:\n",
    "            filtered_results.append((doc, similarity_score))\n",
    "    \n",
    "    print(f\"找到 {len(filtered_results)} 個高相關文件（相似度 ≥ {score_threshold}）：\")\n",
    "    for i, (doc, similarity) in enumerate(filtered_results):\n",
    "        print(f\"\\n{i+1}. 相似度：{similarity:.3f}\")\n",
    "        print(f\"   [{doc.metadata['category']} - {doc.metadata['difficulty']}]\")\n",
    "        print(f\"   內容：{doc.page_content[:80]}...\")\n",
    "    \n",
    "    return filtered_results\n",
    "\n",
    "# 測試帶分數的搜尋\n",
    "test_similarity_search_with_score(\"機器學習演算法\", k=4, score_threshold=0.8)\n",
    "test_similarity_search_with_score(\"人工智慧的未來發展\", k=4, score_threshold=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1501c36",
   "metadata": {},
   "source": [
    "### 元資料過濾搜尋\n",
    "\n",
    "向量資料庫的一個強大功能是能夠結合語義搜尋和元資料過濾："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c246776",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 基於元資料的過濾搜尋\n",
    "def filtered_search(query, filters=None, k=3):\n",
    "    print(f\"\\n=== 過濾搜尋：「{query}」 ===\")\n",
    "    if filters:\n",
    "        print(f\"過濾條件：{filters}\")\n",
    "    \n",
    "    # 執行過濾搜尋\n",
    "    if filters:\n",
    "        results = vector_store.similarity_search(query, k=k, filter=filters)\n",
    "    else:\n",
    "        results = vector_store.similarity_search(query, k=k)\n",
    "    \n",
    "    print(f\"找到 {len(results)} 個符合條件的文件：\")\n",
    "    for i, doc in enumerate(results):\n",
    "        print(f\"\\n{i+1}. [{doc.metadata['category']} - {doc.metadata['difficulty']}]\")\n",
    "        print(f\"   來源：{doc.metadata['source']}\")\n",
    "        print(f\"   內容：{doc.page_content[:60]}...\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# 測試不同的過濾條件\n",
    "print(\"1. 只搜尋技術類文件：\")\n",
    "filtered_search(\"機器學習\", filters={\"category\": \"技術\"})\n",
    "\n",
    "print(\"\\n2. 只搜尋初級難度的文件：\")\n",
    "filtered_search(\"人工智慧\", filters={\"difficulty\": \"初級\"})\n",
    "\n",
    "print(\"\\n3. 搜尋進階技術文件：\")\n",
    "filtered_search(\"深度學習\", filters={\"category\": \"技術\", \"difficulty\": \"進階\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb632f77",
   "metadata": {},
   "source": [
    "## 動手實作、第一個向量資料庫"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac99f58",
   "metadata": {},
   "source": [
    "### 導入套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd44bf80",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0c1d36",
   "metadata": {},
   "source": [
    "### 建立向量資料庫知識"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28033416",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class VectorKnowledgeBase:\n",
    "    \"\"\"完整的向量知識庫類別\"\"\"\n",
    "    \n",
    "    def __init__(self, collection_name=\"knowledge_base\", persist_directory=\"./vector_db\"):\n",
    "        self.collection_name = collection_name\n",
    "        self.persist_directory = persist_directory\n",
    "        self.embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=800,\n",
    "            chunk_overlap=100,\n",
    "            separators=[\"\\n## \", \"\\n### \", \"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "        )\n",
    "        self.vector_store = None\n",
    "        self.document_count = 0\n",
    "        \n",
    "    def create_comprehensive_documents(self):\n",
    "        \"\"\"創建包含多種主題的綜合文件集\"\"\"\n",
    "        documents_data = [\n",
    "            {\n",
    "                \"content\": \"\"\"\n",
    "# 機器學習基礎指南\n",
    "\n",
    "## 什麼是機器學習\n",
    "機器學習是人工智慧的一個分支，它使計算機能夠在不被明確編程的情況下從數據中學習。機器學習演算法建立基於訓練數據的數學模型，以便對新數據進行預測或決策。\n",
    "## 機器學習的類型\n",
    "### 監督式學習\n",
    "監督式學習使用標記的訓練數據來學習輸入和輸出之間的映射關係。常見的監督式學習任務包括分類和回歸。\n",
    "\n",
    "### 無監督式學習\n",
    "無監督式學習從無標記的數據中發現隱藏的模式。聚類和降維是常見的無監督式學習任務。\n",
    "\n",
    "### 強化學習\n",
    "強化學習通過與環境互動來學習，系統通過試錯來最大化累積獎勵。\n",
    "                \"\"\",\n",
    "                \"metadata\": {\n",
    "                    \"source\": \"ml_basics.md\",\n",
    "                    \"category\": \"機器學習\",\n",
    "                    \"level\": \"入門\",\n",
    "                    \"author\": \"AI Lab\",\n",
    "                    \"created_date\": \"2024-01-15\"\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"content\": \"\"\"\n",
    "# 深度學習與神經網路\n",
    "\n",
    "## 神經網路基礎\n",
    "人工神經網路是受生物神經系統啟發的計算模型。它由相互連接的節點（神經元）組成，每個連接都有權重。\n",
    "\n",
    "## 深度學習的突破\n",
    "深度學習使用多層神經網路（通常超過三層）來學習數據的複雜模式。近年來，深度學習在電腦視覺、自然語言處理和語音識別等領域取得了革命性的進展。\n",
    "\n",
    "## 常見的深度學習架構\n",
    "### 卷積神經網路 (CNN)\n",
    "CNN 特別適合處理圖像數據，使用卷積層來檢測局部特徵。\n",
    "\n",
    "### 循環神經網路 (RNN)\n",
    "RNN 適合處理序列數據，如時間序列或自然語言文本。\n",
    "\n",
    "### Transformer\n",
    "Transformer 架構徹底改變了自然語言處理領域，是 GPT 和 BERT 等模型的基礎。\n",
    "                \"\"\",\n",
    "                \"metadata\": {\n",
    "                    \"source\": \"deep_learning.md\",\n",
    "                    \"category\": \"深度學習\",\n",
    "                    \"level\": \"進階\",\n",
    "                    \"author\": \"Neural Network Research Group\",\n",
    "                    \"created_date\": \"2024-02-01\"\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"content\": \"\"\"\n",
    "# 數據科學與分析\n",
    "\n",
    "## 數據科學流程\n",
    "數據科學是一個跨學科領域，結合了統計學、電腦科學和領域專業知識來從數據中提取洞察。\n",
    "\n",
    "### 數據收集\n",
    "數據收集是數據科學的第一步，包括識別相關數據源、設計收集策略和確保數據品質。\n",
    "\n",
    "### 數據預處理\n",
    "數據預處理包括清理、轉換和準備數據以供分析。這通常是最耗時的步驟，但對最終結果的品質至關重要。\n",
    "\n",
    "### 探索性數據分析\n",
    "探索性數據分析（EDA）幫助數據科學家理解數據的結構、模式和異常。視覺化是 EDA 的重要工具。\n",
    "\n",
    "### 模型建立與驗證\n",
    "選擇適當的演算法、訓練模型並評估其性能是數據科學流程的核心。\n",
    "\n",
    "## 數據視覺化\n",
    "有效的數據視覺化能夠揭示數據中的模式，並幫助傳達分析結果。常用的工具包括 Matplotlib、Seaborn 和 Plotly。\n",
    "                \"\"\",\n",
    "                \"metadata\": {\n",
    "                    \"source\": \"data_science.md\",\n",
    "                    \"category\": \"數據科學\",\n",
    "                    \"level\": \"中級\",\n",
    "                    \"author\": \"Data Analytics Team\",\n",
    "                    \"created_date\": \"2024-01-20\"\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"content\": \"\"\"\n",
    "# AI 倫理與社會影響\n",
    "\n",
    "## 人工智慧倫理的重要性\n",
    "隨著人工智慧技術的快速發展和廣泛應用，AI 倫理成為越來越重要的議題。我們需要確保 AI 系統的發展和部署符合人類價值觀和社會利益。\n",
    "\n",
    "## 主要倫理議題\n",
    "### 偏見與公平性\n",
    "AI 系統可能會反映和放大訓練數據中的偏見，導致不公平的結果。確保演算法公平性是 AI 倫理的核心議題。\n",
    "\n",
    "### 透明度與可解釋性\n",
    "許多 AI 系統，特別是深度學習模型，被視為「黑盒子」。提高 AI 決策的透明度和可解釋性對建立信任至關重要。\n",
    "\n",
    "### 隱私保護\n",
    "AI 系統通常需要大量個人數據進行訓練，如何在利用數據的同時保護個人隱私是一個重大挑戰。\n",
    "\n",
    "### 責任歸屬\n",
    "當 AI 系統做出錯誤決策時，如何確定責任歸屬？這涉及法律、技術和倫理多個層面的考量。\n",
    "\n",
    "## 負責任的 AI 發展\n",
    "建立負責任的 AI 發展框架需要技術專家、政策制定者、倫理學家和社會各界的共同努力。\n",
    "                \"\"\",\n",
    "                \"metadata\": {\n",
    "                    \"source\": \"ai_ethics.md\",\n",
    "                    \"category\": \"AI 倫理\",\n",
    "                    \"level\": \"專業\",\n",
    "                    \"author\": \"Ethics in AI Institute\",\n",
    "                    \"created_date\": \"2024-02-10\"\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"content\": \"\"\"\n",
    "# 自然語言處理技術\n",
    "\n",
    "## NLP 概述\n",
    "自然語言處理（NLP）是人工智慧的一個分支，專注於讓計算機理解、解釋和生成人類語言。NLP 結合了語言學、電腦科學和認知科學的知識。\n",
    "\n",
    "## 核心技術\n",
    "### 文本預處理\n",
    "文本預處理包括分詞、詞性標註、命名實體識別等基本任務，為後續分析奠定基礎。\n",
    "\n",
    "### 語言模型\n",
    "語言模型能夠預測文本中下一個詞或評估文本序列的概率。近年來，大型語言模型如 GPT 系列展現了驚人的能力。\n",
    "\n",
    "### 情感分析\n",
    "情感分析可以識別文本中表達的情感傾向，廣泛應用於社交媒體監控、客戶回饋分析等領域。\n",
    "\n",
    "### 機器翻譯\n",
    "神經機器翻譯系統使用深度學習技術，在翻譯品質上取得了顯著提升。\n",
    "\n",
    "## 應用領域\n",
    "NLP 技術廣泛應用於搜尋引擎、聊天機器人、內容推薦、語音助理等產品和服務中。\n",
    "\n",
    "## 挑戰與未來\n",
    "儘管 NLP 取得了巨大進展，但在理解語言的語境、諷刺、文化背景等方面仍面臨挑戰。\n",
    "                \"\"\",\n",
    "                \"metadata\": {\n",
    "                    \"source\": \"nlp_guide.md\",\n",
    "                    \"category\": \"自然語言處理\",\n",
    "                    \"level\": \"中級\",\n",
    "                    \"author\": \"NLP Research Lab\",\n",
    "                    \"created_date\": \"2024-01-25\"\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        documents = []\n",
    "        for doc_data in documents_data:\n",
    "            doc = Document(\n",
    "                page_content=doc_data[\"content\"],\n",
    "                metadata=doc_data[\"metadata\"]\n",
    "            )\n",
    "            documents.append(doc)\n",
    "        \n",
    "        return documents\n",
    "    \n",
    "    def build_knowledge_base(self):\n",
    "        \"\"\"建立完整的向量知識庫\"\"\"\n",
    "        print(\"開始建立向量知識庫...\")\n",
    "        \n",
    "        # 1. 創建文件\n",
    "        documents = self.create_comprehensive_documents()\n",
    "        print(f\"創建了 {len(documents)} 個源文件\")\n",
    "        \n",
    "        # 2. 文件分割\n",
    "        all_chunks = []\n",
    "        for doc in documents:\n",
    "            chunks = self.text_splitter.split_documents([doc])\n",
    "            print(f\"文件 '{doc.metadata['source']}' 分割成 {len(chunks)} 個片段\")\n",
    "            all_chunks.extend(chunks)\n",
    "        \n",
    "        print(f\"總共分割成 {len(all_chunks)} 個文件片段\")\n",
    "        \n",
    "        # 3. 建立向量資料庫\n",
    "        self.vector_store = Chroma.from_documents(\n",
    "            documents=all_chunks,\n",
    "            embedding=self.embeddings,\n",
    "            persist_directory=self.persist_directory,\n",
    "            collection_name=self.collection_name\n",
    "        )\n",
    "        \n",
    "        self.document_count = len(all_chunks)\n",
    "        print(f\"向量知識庫建立完成！共包含 {self.document_count} 個向量化片段\")\n",
    "        \n",
    "        return self.vector_store\n",
    "    \n",
    "    def search(self, query, k=5, category_filter=None, level_filter=None):\n",
    "        \"\"\"智慧搜尋功能\"\"\"\n",
    "        if not self.vector_store:\n",
    "            raise ValueError(\"知識庫尚未建立，請先執行 build_knowledge_base()\")\n",
    "        \n",
    "        print(f\"\\n=== 搜尋查詢：「{query}」 ===\")\n",
    "        \n",
    "        # 構建過濾條件\n",
    "        filters = {}\n",
    "        if category_filter:\n",
    "            filters[\"category\"] = category_filter\n",
    "        if level_filter:\n",
    "            filters[\"level\"] = level_filter\n",
    "        \n",
    "        if filters:\n",
    "            print(f\"過濾條件：{filters}\")\n",
    "            results = self.vector_store.similarity_search(query, k=k, filter=filters)\n",
    "        else:\n",
    "            results = self.vector_store.similarity_search(query, k=k)\n",
    "        \n",
    "        print(f\"找到 {len(results)} 個相關結果：\")\n",
    "        \n",
    "        for i, doc in enumerate(results):\n",
    "            print(f\"\\n--- 結果 {i+1} ---\")\n",
    "            print(f\"來源：{doc.metadata['source']}\")\n",
    "            print(f\"類別：{doc.metadata['category']} | 級別：{doc.metadata['level']}\")\n",
    "            print(f\"作者：{doc.metadata['author']}\")\n",
    "            print(f\"內容摘要：{doc.page_content[:120]}...\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def get_statistics(self):\n",
    "        \"\"\"獲取知識庫統計資訊\"\"\"\n",
    "        if not self.vector_store:\n",
    "            return \"知識庫尚未建立\"\n",
    "        \n",
    "        # 這裡我們模擬統計，實際實作可能需要查詢資料庫\n",
    "        stats = {\n",
    "            \"total_documents\": self.document_count,\n",
    "            \"collection_name\": self.collection_name,\n",
    "            \"storage_location\": self.persist_directory\n",
    "        }\n",
    "        \n",
    "        return stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64406055",
   "metadata": {},
   "source": [
    "### 實例化並建立知識庫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f1f44a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 實例化並建立知識庫\n",
    "print(\"正在建立綜合向量知識庫...\")\n",
    "kb = VectorKnowledgeBase(collection_name=\"ai_comprehensive_kb\")\n",
    "vector_store = kb.build_knowledge_base()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a802c81e",
   "metadata": {},
   "source": [
    "## 測試檢索功能"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1a8b42",
   "metadata": {},
   "source": [
    "### 測試基本搜尋功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2f0d50",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"=== 基本搜尋測試 ===\")\n",
    "kb.search(\"什麼是神經網路？\", k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af76be36",
   "metadata": {},
   "source": [
    "### 測試分類過濾搜尋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa54a1a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 測試分類過濾搜尋\n",
    "print(\"\\n=== 分類過濾搜尋測試 ===\")\n",
    "kb.search(\"數據分析\", k=3, category_filter=\"數據科學\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b36c71",
   "metadata": {},
   "source": [
    "### 測試級別過濾搜尋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957450f4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 測試級別過濾搜尋\n",
    "print(\"\\n=== 級別過濾搜尋測試 ===\")\n",
    "kb.search(\"機器學習\", k=3, level_filter=\"入門\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd48145",
   "metadata": {},
   "source": [
    "### 測試複合過濾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06734b4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 測試複合過濾\n",
    "print(\"\\n=== 複合過濾搜尋測試 ===\")\n",
    "kb.search(\"演算法\", k=2, category_filter=\"深度學習\", level_filter=\"進階\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc05e74",
   "metadata": {},
   "source": [
    "### 測試語義理解能力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f6591f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 測試語義理解能力\n",
    "print(\"\\n=== 語義理解能力測試 ===\")\n",
    "semantic_queries = [\n",
    "    \"AI 的道德問題\",\n",
    "    \"如何確保人工智慧的公平性？\",\n",
    "    \"深度神經網路的架構\",\n",
    "    \"數據清理和準備\",\n",
    "    \"語言模型的應用\"\n",
    "]\n",
    "\n",
    "for query in semantic_queries:\n",
    "    print(f\"\\n查詢：{query}\")\n",
    "    results = kb.search(query, k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25350b0",
   "metadata": {},
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aca69b2",
   "metadata": {},
   "source": [
    "## 進階檢索功能實作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ae0aac",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class AdvancedVectorKnowledgeBase(VectorKnowledgeBase):\n",
    "    \"\"\"具有進階功能的向量知識庫\"\"\"\n",
    "    \n",
    "    def semantic_similarity_analysis(self, query, threshold=0.7):\n",
    "        \"\"\"語義相似度分析\"\"\"\n",
    "        print(f\"\\n=== 語義相似度分析：「{query}」 ===\")\n",
    "        \n",
    "        # 獲取查詢的嵌入向量\n",
    "        query_embedding = self.embeddings.embed_query(query)\n",
    "        \n",
    "        # 執行帶分數的搜尋\n",
    "        results_with_scores = self.vector_store.similarity_search_with_score(query, k=10)\n",
    "        \n",
    "        # 過濾高相似度結果\n",
    "        high_similarity_results = []\n",
    "        for doc, score in results_with_scores:\n",
    "            # 轉換距離分數為相似度分數\n",
    "            similarity = 1 / (1 + score)\n",
    "            if similarity >= threshold:\n",
    "                high_similarity_results.append((doc, similarity))\n",
    "        \n",
    "        print(f\"找到 {len(high_similarity_results)} 個高相似度結果（≥ {threshold}）：\")\n",
    "        \n",
    "        for i, (doc, similarity) in enumerate(high_similarity_results):\n",
    "            print(f\"\\n{i+1}. 相似度：{similarity:.3f}\")\n",
    "            print(f\"   類別：{doc.metadata['category']}\")\n",
    "            print(f\"   來源：{doc.metadata['source']}\")\n",
    "            print(f\"   內容：{doc.page_content[:100]}...\")\n",
    "        \n",
    "        return high_similarity_results\n",
    "    \n",
    "    def multi_query_search(self, queries, k_per_query=3):\n",
    "        \"\"\"多查詢聚合搜尋\"\"\"\n",
    "        print(f\"\\n=== 多查詢聚合搜尋 ===\")\n",
    "        print(f\"查詢列表：{queries}\")\n",
    "        \n",
    "        all_results = []\n",
    "        seen_content = set()\n",
    "        \n",
    "        for query in queries:\n",
    "            results = self.vector_store.similarity_search(query, k=k_per_query)\n",
    "            for doc in results:\n",
    "                # 去重：避免重複的文件片段\n",
    "                content_hash = hash(doc.page_content)\n",
    "                if content_hash not in seen_content:\n",
    "                    seen_content.add(content_hash)\n",
    "                    all_results.append(doc)\n",
    "        \n",
    "        print(f\"聚合去重後共 {len(all_results)} 個結果：\")\n",
    "        \n",
    "        for i, doc in enumerate(all_results[:8]):  # 只顯示前8個\n",
    "            print(f\"\\n{i+1}. [{doc.metadata['category']}] {doc.metadata['source']}\")\n",
    "            print(f\"   {doc.page_content[:80]}...\")\n",
    "        \n",
    "        return all_results\n",
    "    \n",
    "    def category_overview(self):\n",
    "        \"\"\"知識庫分類概覽\"\"\"\n",
    "        print(f\"\\n=== 知識庫分類概覽 ===\")\n",
    "        \n",
    "        # 這裡我們使用模擬數據，實際應用中可以查詢資料庫獲取統計\n",
    "        categories = [\"機器學習\", \"深度學習\", \"數據科學\", \"AI 倫理\", \"自然語言處理\"]\n",
    "        \n",
    "        for category in categories:\n",
    "            results = self.vector_store.similarity_search(\n",
    "                f\"{category}相關內容\", \n",
    "                k=100, \n",
    "                filter={\"category\": category}\n",
    "            )\n",
    "            print(f\"{category}：{len(results)} 個文件片段\")\n",
    "        \n",
    "        return categories\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca92a8a7",
   "metadata": {},
   "source": [
    "### 升級到進階知識庫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085336be",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 升級到進階知識庫\n",
    "advanced_kb = AdvancedVectorKnowledgeBase(collection_name=\"ai_comprehensive_kb\")\n",
    "advanced_kb.vector_store = kb.vector_store\n",
    "advanced_kb.document_count = kb.document_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536607fb",
   "metadata": {},
   "source": [
    "### 測試功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e475f312",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 測試進階功能\n",
    "advanced_kb.semantic_similarity_analysis(\"人工智慧的倫理考量\", threshold=0.75)\n",
    "\n",
    "advanced_kb.multi_query_search([\n",
    "    \"機器學習演算法\",\n",
    "    \"數據預處理\",\n",
    "    \"模型評估\"\n",
    "], k_per_query=2)\n",
    "\n",
    "advanced_kb.category_overview()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
